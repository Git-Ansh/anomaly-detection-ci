{
  "permissions": {
    "allow": [
      "Bash(python:*)",
      "Bash(venvScriptspip install pandas numpy scikit-learn xgboost matplotlib seaborn ruptures scipy)",
      "Bash(venv/Scripts/pip install:*)",
      "Bash(venv/Scripts/python:*)",
      "Bash(../venv/Scripts/python:*)",
      "Bash(../Doc_ansh/Doc_ansh/venv/Scripts/python:*)",
      "Bash(dir /s /b /ad \"C:\\\\Users\\\\anshj\\\\Downloads\\\\Doc_ansh\\\\Doc_ansh\\\\Doc_ansh\")",
      "Bash(findstr:*)",
      "Bash(done)",
      "Bash(ls:*)",
      "WebSearch",
      "WebFetch(domain:arxiv.org)",
      "WebFetch(domain:conf.researchr.org)",
      "WebFetch(domain:firefox-source-docs.mozilla.org)",
      "WebFetch(domain:wiki.mozilla.org)",
      "Bash(find:*)",
      "Bash(python3:*)",
      "Bash(source:*)",
      "Bash(pip3 install:*)",
      "Bash(conda info:*)",
      "Bash(/home/zephyrus/perf-regression-ci/venv/Scripts/python.exe:*)",
      "Bash(pdflatex:*)",
      "Bash(apt list:*)",
      "Bash(dpkg -l:*)",
      "WebFetch(domain:icpe2026.spec.org)",
      "WebFetch(domain:github.com)",
      "WebFetch(domain:defect-datasets.github.io)",
      "WebFetch(domain:smartshark.github.io)",
      "Bash(pip3 list:*)",
      "Bash(/home/zephyrus/perf-regression-ci/venv/Lib/../Scripts/python.exe:*)",
      "Bash(venv/Scripts/python.exe:*)",
      "Bash(xargs:*)",
      "Bash(sort:*)",
      "Bash(wc:*)",
      "Bash(1 <<'PYEOF'\nimport numpy as np, pandas as pd, sys, warnings\nwarnings.filterwarnings\\('ignore'\\)\nsys.path.insert\\(0, 'src'\\)\nfrom cascade.data.loader import prepare_cascade_data\nfrom cascade.stages.stage_0_invalid_filter import train_stage_0, predict_stage_0\n\ndata = prepare_cascade_data\\(\\)\nartifacts = train_stage_0\\(data['train_summaries']\\)\ntest_preds = predict_stage_0\\(artifacts, data['test_summaries']\\)\n\ntruly_invalid = test_preds[test_preds['alert_summary_status'] == 3].copy\\(\\)\ncaught = truly_invalid[truly_invalid['s0_pred'] == 3]\nmissed = truly_invalid[truly_invalid['s0_pred'] != 3]\nall_valid = test_preds[test_preds['alert_summary_status'] != 3]\n\nprint\\(f'Total Invalid in test: {len\\(truly_invalid\\)}'\\)\nprint\\(f'Caught \\(s0_pred=3\\): {len\\(caught\\)}'\\)\nprint\\(f'Missed as Valid \\(s0_pred=0\\): {\\(missed[\"s0_pred\"]==0\\).sum\\(\\)}'\\)\nprint\\(f'Deferred \\(s0_pred=-1\\): {\\(missed[\"s0_pred\"]==-1\\).sum\\(\\)}'\\)\nprint\\(\\)\n\nkey_features = ['group_size', 'is_single_alert', 'magnitude_mean', 'magnitude_max',\n                'pct_change_mean', 't_value_mean', 't_value_max',\n                'regression_ratio', 'n_unique_suites', 'noise_ratio',\n                'manually_created_ratio']\n\nprint\\('Feature medians: CAUGHT vs MISSED vs VALID'\\)\nfor f in key_features:\n    if f in caught.columns:\n        print\\(f'  {f:<26} caught={caught[f].median\\(\\):<10.3f} missed={missed[f].median\\(\\):<10.3f} valid={all_valid[f].median\\(\\):<10.3f}'\\)\n\nprint\\(\\)\nproba_inv = missed['s0_proba_invalid']\nprint\\('s0_proba_invalid for MISSED:'\\)\nfor t in [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n    c = \\(proba_inv >= t\\).sum\\(\\)\n    print\\(f'  >= {t}: {c}/{len\\(missed\\)} \\({c/len\\(missed\\)*100:.1f}%\\)'\\)\n\nprint\\(\\)\nproba_inv_c = caught['s0_proba_invalid']\nprint\\('s0_proba_invalid for CAUGHT:'\\)\nfor t in [0.5, 0.7, 0.8, 0.9]:\n    c = \\(proba_inv_c >= t\\).sum\\(\\)\n    print\\(f'  >= {t}: {c}/{len\\(caught\\)} \\({c/len\\(caught\\)*100:.1f}%\\)'\\)\n\nprint\\(\\)\nprint\\(f'Per-class thresholds: {artifacts[\"threshold\"]}'\\)\nprint\\(f'Global threshold: {artifacts[\"global_threshold\"]}'\\)\n\nprint\\(\\)\nprint\\('Suite distribution:'\\)\nprint\\('  CAUGHT top suites:'\\)\nfor s, c in caught['dominant_suite'].value_counts\\(\\).head\\(5\\).items\\(\\):\n    print\\(f'    {s}: {c}'\\)\nprint\\('  MISSED top suites:'\\)\nfor s, c in missed['dominant_suite'].value_counts\\(\\).head\\(5\\).items\\(\\):\n    print\\(f'    {s}: {c}'\\)\nPYEOF)",
      "Bash(1 <<'PYEOF'\nimport pandas as pd, sys, warnings\nwarnings.filterwarnings\\('ignore'\\)\nsys.path.insert\\(0, 'src'\\)\nfrom cascade.data.loader import prepare_cascade_data\n\ndata = prepare_cascade_data\\(\\)\n\n# Repository distribution\nprint\\(\"=== Repository distribution \\(all resolved\\) ===\"\\)\ntrain = data['train_summaries']\ntest = data['test_summaries']\nall_resolved = pd.concat\\([train, test]\\)\n\nprint\\(\"\\\\nTRAIN set repos:\"\\)\nfor repo, count in train['repository'].value_counts\\(\\).items\\(\\):\n    inv = \\(train[train['repository']==repo]['alert_summary_status']==3\\).sum\\(\\)\n    print\\(f\"  {repo}: {count} summaries \\({inv} Invalid\\)\"\\)\n\nprint\\(\"\\\\nTEST set repos:\"\\)\nfor repo, count in test['repository'].value_counts\\(\\).items\\(\\):\n    inv = \\(test[test['repository']==repo]['alert_summary_status']==3\\).sum\\(\\)\n    print\\(f\"  {repo}: {count} summaries \\({inv} Invalid\\)\"\\)\n\nprint\\(\"\\\\nALL resolved repos:\"\\)\nfor repo, count in all_resolved['repository'].value_counts\\(\\).items\\(\\):\n    print\\(f\"  {repo}: {count}\"\\)\nPYEOF)",
      "Bash(1 <<'PYEOF'\nimport pandas as pd\n# Check what one timeseries file looks like\ndf = pd.read_csv\\('data/timeseries-data/autoland1/autoland1/4768977_timeseries_data.csv'\\)\nprint\\(f\"Shape: {df.shape}\"\\)\nprint\\(f\"Columns: {list\\(df.columns\\)}\"\\)\nprint\\(df.head\\(3\\)\\)\nprint\\(f\"\\\\nSignature ID from filename: 4768977\"\\)\n\n# Check how many TS files we have across all repos\nimport os\ntotal = 0\nfor repo_dir in ['autoland1', 'autoland2', 'autoland3', 'autoland4', \n                  'firefox-android', 'mozilla-beta', 'mozilla-central', 'mozilla-release']:\n    subdir = f'data/timeseries-data/{repo_dir}/{repo_dir}'\n    if os.path.isdir\\(subdir\\):\n        count = len\\([f for f in os.listdir\\(subdir\\) if f.endswith\\('.csv'\\)]\\)\n        total += count\n        print\\(f\"  {repo_dir}: {count} TS files\"\\)\nprint\\(f\"  TOTAL: {total} TS files\"\\)\n\n# Check how alerts map to signatures\nalerts = pd.read_csv\\('data/alerts_data.csv'\\)\nn_sigs = alerts['signature_id'].nunique\\(\\)\nprint\\(f\"\\\\nAlerts have {n_sigs} unique signatures\"\\)\nprint\\(f\"Total alerts: {len\\(alerts\\)}\"\\)\nPYEOF)",
      "Bash(1 <<'PYEOF'\nimport pandas as pd, os\n\n# Check which repo directory contains which signature\nalerts = pd.read_csv\\('data/alerts_data.csv'\\)\nsig_to_repo_dir = {}\nbase = 'data/timeseries-data'\nfor repo_dir in ['autoland1', 'autoland2', 'autoland3', 'autoland4',\n                  'firefox-android', 'mozilla-beta', 'mozilla-central', 'mozilla-release']:\n    subdir = os.path.join\\(base, repo_dir, repo_dir\\)\n    if os.path.isdir\\(subdir\\):\n        for f in os.listdir\\(subdir\\):\n            if f.endswith\\('_timeseries_data.csv'\\):\n                sig_id = int\\(f.split\\('_'\\)[0]\\)\n                sig_to_repo_dir[sig_id] = subdir\n\n# Check coverage\nalert_sigs = set\\(alerts['signature_id'].unique\\(\\)\\)\nts_sigs = set\\(sig_to_repo_dir.keys\\(\\)\\)\nprint\\(f\"Alert signatures: {len\\(alert_sigs\\)}\"\\)\nprint\\(f\"TS files: {len\\(ts_sigs\\)}\"\\)\nprint\\(f\"Overlap: {len\\(alert_sigs & ts_sigs\\)}\"\\)\nprint\\(f\"Missing: {len\\(alert_sigs - ts_sigs\\)}\"\\)\n\n# Check a sample TS file more closely - how much data before alert?\nsig = list\\(alert_sigs & ts_sigs\\)[0]\nts_df = pd.read_csv\\(os.path.join\\(sig_to_repo_dir[sig], f'{sig}_timeseries_data.csv'\\)\\)\nprint\\(f\"\\\\nSample sig {sig}: {len\\(ts_df\\)} data points\"\\)\nprint\\(f\"  Columns with 'value': {[c for c in ts_df.columns if 'value' in c.lower\\(\\)]}\"\\)\nts_df['push_timestamp'] = pd.to_datetime\\(ts_df['push_timestamp']\\)\nprint\\(f\"  Date range: {ts_df['push_timestamp'].min\\(\\)} to {ts_df['push_timestamp'].max\\(\\)}\"\\)\n\n# The 'value' column is the measurement\nprint\\(f\"  value stats: mean={ts_df['value'].mean\\(\\):.2f}, std={ts_df['value'].std\\(\\):.2f}\"\\)\nPYEOF)",
      "Bash(1 <<'PYEOF'\nimport sys, warnings, numpy as np, pandas as pd\nwarnings.filterwarnings\\('ignore'\\)\nsys.path.insert\\(0, 'src'\\)\n\nfrom cascade.data.loader import prepare_cascade_data\nfrom cascade.stages.stage_0_invalid_filter import \\(\n    train_stage_0, predict_stage_0, prepare_stage_0_data,\n    compute_suite_invalid_rates, STAGE_0_TS_FEATURES, SUITE_INVALID_RATE_COL\n\\)\n\ndata = prepare_cascade_data\\(\\)\ntrain = data['train_summaries']\ntest = data['test_summaries']\ntrue_invalid = \\(test['alert_summary_status'] == 3\\).values\n\n# --- Config A: Original \\(no TS, no suite rate\\) ---\nprint\\(\"=== A: ORIGINAL \\(no TS, no suite\\) ===\", flush=True\\)\ntrain_a = train.drop\\(columns=[c for c in train.columns if 'ts_' in c], errors='ignore'\\)\ntest_a = test.drop\\(columns=[c for c in test.columns if 'ts_' in c], errors='ignore'\\)\n# Temporarily remove suite rate computation\nimport cascade.stages.stage_0_invalid_filter as s0_mod\norig_func = s0_mod.compute_suite_invalid_rates\ns0_mod.compute_suite_invalid_rates = lambda df: {}\nart_a = train_stage_0\\(train_a\\)\npred_a = predict_stage_0\\(art_a, test_a\\)\ns0_mod.compute_suite_invalid_rates = orig_func\n\npi_a = \\(pred_a['s0_pred'] == 3\\).values\nprec_a = true_invalid[pi_a].mean\\(\\) if pi_a.sum\\(\\) > 0 else 0\nrec_a = pi_a[true_invalid].mean\\(\\) if true_invalid.sum\\(\\) > 0 else 0\nprint\\(f\"  Caught: {pi_a.sum\\(\\)}, Precision: {prec_a:.3f}, Recall: {rec_a:.3f}\", flush=True\\)\n\n# --- Config B: Suite rate only \\(no TS\\) ---\nprint\\(\"\\\\n=== B: SUITE RATE ONLY \\(no TS\\) ===\", flush=True\\)\ntrain_b = train.drop\\(columns=[c for c in train.columns if 'ts_' in c], errors='ignore'\\)\ntest_b = test.drop\\(columns=[c for c in test.columns if 'ts_' in c], errors='ignore'\\)\nart_b = train_stage_0\\(train_b\\)\npred_b = predict_stage_0\\(art_b, test_b\\)\n\npi_b = \\(pred_b['s0_pred'] == 3\\).values\nprec_b = true_invalid[pi_b].mean\\(\\) if pi_b.sum\\(\\) > 0 else 0\nrec_b = pi_b[true_invalid].mean\\(\\) if true_invalid.sum\\(\\) > 0 else 0\nprint\\(f\"  Caught: {pi_b.sum\\(\\)}, Precision: {prec_b:.3f}, Recall: {rec_b:.3f}\", flush=True\\)\n\n# --- Config C: TS features only \\(no suite rate\\) ---\nprint\\(\"\\\\n=== C: TS FEATURES ONLY \\(no suite\\) ===\", flush=True\\)\ns0_mod.compute_suite_invalid_rates = lambda df: {}\nart_c = train_stage_0\\(train\\)\npred_c = predict_stage_0\\(art_c, test\\)\ns0_mod.compute_suite_invalid_rates = orig_func\n\npi_c = \\(pred_c['s0_pred'] == 3\\).values\nprec_c = true_invalid[pi_c].mean\\(\\) if pi_c.sum\\(\\) > 0 else 0\nrec_c = pi_c[true_invalid].mean\\(\\) if true_invalid.sum\\(\\) > 0 else 0\nprint\\(f\"  Caught: {pi_c.sum\\(\\)}, Precision: {prec_c:.3f}, Recall: {rec_c:.3f}\", flush=True\\)\n\n# --- Config D: Both TS + suite ---\nprint\\(\"\\\\n=== D: TS + SUITE \\(both\\) ===\", flush=True\\)\nart_d = train_stage_0\\(train\\)\npred_d = predict_stage_0\\(art_d, test\\)\n\npi_d = \\(pred_d['s0_pred'] == 3\\).values\nprec_d = true_invalid[pi_d].mean\\(\\) if pi_d.sum\\(\\) > 0 else 0\nrec_d = pi_d[true_invalid].mean\\(\\) if true_invalid.sum\\(\\) > 0 else 0\nprint\\(f\"  Caught: {pi_d.sum\\(\\)}, Precision: {prec_d:.3f}, Recall: {rec_d:.3f}\", flush=True\\)\n\n# Summary\nprint\\(\"\\\\n\" + \"=\" * 60, flush=True\\)\nprint\\(\"COMPARISON SUMMARY\", flush=True\\)\nprint\\(\"=\" * 60, flush=True\\)\nprint\\(f\"  {'Config':<25} {'Caught':>8} {'Precision':>10} {'Recall':>8}\", flush=True\\)\nprint\\(f\"  {'-'*51}\", flush=True\\)\nprint\\(f\"  {'A: Original':<25} {pi_a.sum\\(\\):>8} {prec_a:>10.3f} {rec_a:>8.3f}\", flush=True\\)\nprint\\(f\"  {'B: + Suite rate':<25} {pi_b.sum\\(\\):>8} {prec_b:>10.3f} {rec_b:>8.3f}\", flush=True\\)\nprint\\(f\"  {'C: + TS features':<25} {pi_c.sum\\(\\):>8} {prec_c:>10.3f} {rec_c:>8.3f}\", flush=True\\)\nprint\\(f\"  {'D: + Both':<25} {pi_d.sum\\(\\):>8} {prec_d:>10.3f} {rec_d:>8.3f}\", flush=True\\)\nPYEOF)",
      "Skill(keybindings-help)",
      "WebFetch(domain:raw.githubusercontent.com)",
      "Bash(/tmp/per_class_analysis.py << 'PYEOF'\nimport sys\nsys.path.insert\\(0, '/home/zephyrus/perf-regression-ci/src'\\)\nimport numpy as np\nimport pandas as pd\nfrom common.data_paths import RANDOM_SEED\nfrom cascade.data.loader import prepare_cascade_data, SUMMARY_FEATURES\n\nnp.random.seed\\(RANDOM_SEED\\)\ndata = prepare_cascade_data\\(\\)\ntrain = data['train_summaries']\ntest = data['test_summaries']\n\nstatus_names = {1:'Downstream',2:'Reassigned',3:'Invalid',4:'Improvement',6:'Wontfix',7:'Fixed',8:'Backedout'}\n\nprint\\(\"=\" * 70\\)\nprint\\(\"TEST SET GROUND TRUTH\"\\)\nprint\\(\"=\" * 70\\)\nfor code, count in test['alert_summary_status'].value_counts\\(\\).sort_index\\(\\).items\\(\\):\n    print\\(f\"  {status_names.get\\(code,code\\)} \\({code}\\): {count} \\({count/len\\(test\\)*100:.1f}%\\)\"\\)\nprint\\(f\"  Total: {len\\(test\\)}\"\\)\n\n# ---- Stage 0: Invalid ----\nfrom cascade.stages.stage_0_invalid_filter import train_stage_0, predict_stage_0\ns0 = train_stage_0\\(train\\)\ntest_s0 = predict_stage_0\\(s0, test\\)\ntrue_inv = \\(test['alert_summary_status'] == 3\\).values\n\nprint\\(\"\\\\n\" + \"=\" * 70\\)\nprint\\(\"STAGE 0: INVALID FILTER\"\\)\nprint\\(\"=\" * 70\\)\nfor val, name in [\\(1,'Invalid'\\), \\(0,'Valid'\\), \\(-1,'Deferred'\\)]:\n    mask = test_s0['s0_pred'].values == val\n    n = mask.sum\\(\\)\n    if n == 0: continue\n    if val == 1:\n        correct = true_inv[mask].sum\\(\\)\n        print\\(f\"  Predicted {name}: {n}, truly invalid: {correct}/{n} = {correct/n*100:.1f}% precision\"\\)\n    elif val == 0:\n        correct = \\(~true_inv[mask]\\).sum\\(\\)\n        print\\(f\"  Predicted {name}: {n}, truly valid: {correct}/{n} = {correct/n*100:.1f}% precision\"\\)\n    else:\n        print\\(f\"  Deferred: {n}\"\\)\n\nprint\\(f\"  Invalid recall: {true_inv[test_s0['s0_pred'].values==1].sum\\(\\)}/{true_inv.sum\\(\\)} = {true_inv[test_s0['s0_pred'].values==1].sum\\(\\)/true_inv.sum\\(\\)*100:.1f}%\"\\)\n\n# ---- Stage 3: has_bug ----\nfrom cascade.stages.stage_3_bug_linkage import train_stage_3, predict_stage_3\ns3 = train_stage_3\\(train\\)\ntest_s3 = predict_stage_3\\(s3, test.copy\\(\\)\\)\n\nprint\\(\"\\\\n\" + \"=\" * 70\\)\nprint\\(\"STAGE 3: HAS_BUG\"\\)\nprint\\(\"=\" * 70\\)\ntrue_bug = test['has_bug'].values\npred_bug = test_s3['s3_pred'].values\nconf_bug = test_s3['s3_confidence'].values\n\nfor code, name in [\\(0,'No Bug'\\),\\(1,'Has Bug'\\)]:\n    true_n = \\(true_bug == code\\).sum\\(\\)\n    pred_n = \\(pred_bug == code\\).sum\\(\\)\n    correct = \\(\\(true_bug == code\\) & \\(pred_bug == code\\)\\).sum\\(\\)\n    prec = correct/pred_n*100 if pred_n > 0 else 0\n    rec = correct/true_n*100 if true_n > 0 else 0\n    print\\(f\"  {name}: True={true_n}, Predicted={pred_n}, Correct={correct}, Prec={prec:.1f}%, Rec={rec:.1f}%\"\\)\n\nfor t in [0.60, 0.70, 0.80, 0.90]:\n    mask = conf_bug >= t\n    n = mask.sum\\(\\)\n    if n > 0:\n        acc = \\(true_bug[mask] == pred_bug[mask]\\).mean\\(\\)\n        print\\(f\"  t={t:.2f}: {acc*100:.1f}% acc, {n/len\\(test\\)*100:.1f}% cov \\({n} predicted\\)\"\\)\n\n# ---- Now test multiple class configs ----\nfrom cascade.framework.confidence_stage import ConfidenceStage\n\nfeatures = [c for c in SUMMARY_FEATURES if c in train.columns]\nfor extra in ['has_subtests_ratio', 'lower_is_better_ratio']:\n    if extra in train.columns and extra not in features:\n        features.append\\(extra\\)\n\n# Non-Invalid subsets\ntrain_ni = train[train['alert_summary_status'] != 3].copy\\(\\)\ntest_ni = test[test['alert_summary_status'] != 3].copy\\(\\)\n\nconfigs = {\n    '5-class \\(Imp,Reas,Wontfix,Fixed,Down\\)': {\n        'merge': {8: 2},\n        'classes': {1:'Downstream',2:'Reassigned',4:'Improvement',6:'Wontfix',7:'Fixed'},\n    },\n    '4-class \\(Actionable,Wontfix,Fixed,Down\\)': {\n        'merge': {8: 4, 2: 4},\n        'classes': {4:'Actionable',1:'Downstream',6:'Wontfix',7:'Fixed'},\n    },\n    '3-class \\(Inv,Imp,ActionNeeded\\)': {\n        'merge': {8: 0, 2: 0, 6: 0, 7: 0, 1: 0, 3: 2},  # applied to full set\n        'classes': {0:'Action-Needed',4:'Improvement',2:'Invalid'},\n        'full_set': True,\n    },\n    'Binary: Imp vs NonImp': {\n        'merge': {1: 0, 2: 0, 6: 0, 7: 0, 8: 0},\n        'classes': {0:'Non-Improvement',4:'Improvement'},\n    },\n}\n\nfor config_name, cfg in configs.items\\(\\):\n    print\\(\"\\\\n\" + \"=\" * 70\\)\n    print\\(f\"CONFIG: {config_name}\"\\)\n    print\\(\"=\" * 70\\)\n\n    use_full = cfg.get\\('full_set', False\\)\n    tr = train.copy\\(\\) if use_full else train_ni.copy\\(\\)\n    te = test.copy\\(\\) if use_full else test_ni.copy\\(\\)\n\n    tr['target'] = tr['alert_summary_status'].replace\\(cfg['merge']\\)\n    te['target'] = te['alert_summary_status'].replace\\(cfg['merge']\\)\n\n    valid_codes = set\\(cfg['classes'].keys\\(\\)\\)\n    tr = tr[tr['target'].isin\\(valid_codes\\)].copy\\(\\)\n    te = te[te['target'].isin\\(valid_codes\\)].copy\\(\\)\n\n    X_tr = tr[features].fillna\\(0\\).values\n    y_tr = tr['target'].values\n    X_te = te[features].fillna\\(0\\).values\n    y_te = te['target'].values\n\n    print\\(f\"\\\\nTrain: {len\\(tr\\)}, Test: {len\\(te\\)}\"\\)\n    for code in sorted\\(cfg['classes'].keys\\(\\)\\):\n        n_tr = \\(y_tr == code\\).sum\\(\\)\n        n_te = \\(y_te == code\\).sum\\(\\)\n        print\\(f\"  {cfg['classes'][code]} \\({code}\\): train={n_tr}, test={n_te}\"\\)\n\n    majority = max\\(np.bincount\\(y_te.astype\\(int\\) if y_te.min\\(\\) >= 0 else y_te - y_te.min\\(\\), minlength=max\\(valid_codes\\)+1\\)\\) / len\\(y_te\\)\n    print\\(f\"  Majority baseline: {majority*100:.1f}%\"\\)\n\n    stage = ConfidenceStage\\(\n        name=config_name,\n        classes=cfg['classes'],\n        target_accuracy=0.85,\n        random_state=RANDOM_SEED,\n    \\)\n    stage.fit\\(X_tr, y_tr, feature_names=features\\)\n    preds = stage.predict\\(X_te, return_proba=True\\)\n\n    raw = preds['predicted_raw']\n    conf = preds['confidence']\n\n    print\\(f\"\\\\nPer-class \\(raw, no threshold\\):\"\\)\n    for code in sorted\\(cfg['classes'].keys\\(\\)\\):\n        true_m = y_te == code\n        pred_m = raw == code\n        both = true_m & pred_m\n        prec = both.sum\\(\\)/pred_m.sum\\(\\)*100 if pred_m.sum\\(\\) > 0 else 0\n        rec = both.sum\\(\\)/true_m.sum\\(\\)*100 if true_m.sum\\(\\) > 0 else 0\n        print\\(f\"  {cfg['classes'][code]}: True={true_m.sum\\(\\)}, Pred={pred_m.sum\\(\\)}, Correct={both.sum\\(\\)}, Prec={prec:.1f}%, Rec={rec:.1f}%\"\\)\n\n    print\\(f\"\\\\nCoverage-accuracy curve:\"\\)\n    for t in [0.40, 0.50, 0.60, 0.70, 0.80, 0.90]:\n        mask = conf >= t\n        n = mask.sum\\(\\)\n        if n > 0:\n            acc = \\(y_te[mask] == raw[mask]\\).mean\\(\\)\n            print\\(f\"  t={t:.2f}: {acc*100:.1f}% acc, {n/len\\(y_te\\)*100:.1f}% cov \\({n} pred\\)\"\\)\n            # per-class at this threshold\n            for code in sorted\\(cfg['classes'].keys\\(\\)\\):\n                cm = mask & \\(raw == code\\)\n                cn = cm.sum\\(\\)\n                if cn > 0:\n                    cc = \\(y_te[cm] == code\\).sum\\(\\)\n                    print\\(f\"    {cfg['classes'][code]}: {cn} pred, {cc}/{cn} correct \\({cc/cn*100:.1f}%\\)\"\\)\n\nPYEOF)",
      "Bash(/tmp/per_class_analysis.py << 'PYEOF'\nimport sys\nsys.path.insert\\(0, '/home/zephyrus/perf-regression-ci/src'\\)\nimport numpy as np\nimport pandas as pd\nfrom common.data_paths import RANDOM_SEED\nfrom cascade.data.loader import prepare_cascade_data\n\nnp.random.seed\\(RANDOM_SEED\\)\ndata = prepare_cascade_data\\(\\)\ntrain = data['train_summaries']\ntest = data['test_summaries']\n\nFEATURES = [\n    'group_size', 'is_single_alert',\n    'magnitude_mean', 'magnitude_max', 'magnitude_min', 'magnitude_std',\n    'pct_change_mean', 'pct_change_max',\n    't_value_mean', 't_value_max', 't_value_min',\n    'n_regressions', 'regression_ratio',\n    'n_unique_suites', 'n_unique_platforms',\n    'n_manually_created', 'manually_created_ratio',\n    'noise_ratio',\n    'prev_value_mean', 'new_value_mean', 'value_change_ratio',\n    'has_subtests_ratio', 'lower_is_better_ratio',\n]\n\nstatus_names = {1:'Downstream',2:'Reassigned',3:'Invalid',4:'Improvement',6:'Wontfix',7:'Fixed',8:'Backedout'}\n\nprint\\(\"=\" * 70\\)\nprint\\(\"TEST SET GROUND TRUTH\"\\)\nprint\\(\"=\" * 70\\)\nfor code, count in test['alert_summary_status'].value_counts\\(\\).sort_index\\(\\).items\\(\\):\n    print\\(f\"  {status_names.get\\(code,code\\)} \\({code}\\): {count} \\({count/len\\(test\\)*100:.1f}%\\)\"\\)\nprint\\(f\"  Total: {len\\(test\\)}\"\\)\n\n# ---- Stage 0: Invalid ----\nfrom cascade.stages.stage_0_invalid_filter import train_stage_0, predict_stage_0\ns0 = train_stage_0\\(train\\)\ntest_s0 = predict_stage_0\\(s0, test\\)\ntrue_inv = \\(test['alert_summary_status'] == 3\\).values\n\nprint\\(\"\\\\n\" + \"=\" * 70\\)\nprint\\(\"STAGE 0: INVALID FILTER\"\\)\nprint\\(\"=\" * 70\\)\npred_s0 = test_s0['s0_pred'].values\nfor val, name in [\\(1,'Invalid'\\), \\(0,'Valid'\\), \\(-1,'Deferred'\\)]:\n    mask = pred_s0 == val\n    n = mask.sum\\(\\)\n    if n == 0: continue\n    if val == 1:\n        correct = true_inv[mask].sum\\(\\)\n        print\\(f\"  Predicted {name}: {n}, truly invalid: {correct}/{n} = {correct/n*100:.1f}% precision\"\\)\n    elif val == 0:\n        correct = \\(~true_inv[mask]\\).sum\\(\\)\n        print\\(f\"  Predicted {name}: {n}, truly valid: {correct}/{n} = {correct/n*100:.1f}% precision\"\\)\n    else:\n        print\\(f\"  Deferred: {n}\"\\)\nprint\\(f\"  Invalid recall: {true_inv[pred_s0==1].sum\\(\\)}/{true_inv.sum\\(\\)} = {true_inv[pred_s0==1].sum\\(\\)/true_inv.sum\\(\\)*100:.1f}%\"\\)\n\n# ---- Stage 3: has_bug ----\nfrom cascade.stages.stage_3_bug_linkage import train_stage_3, predict_stage_3\ns3 = train_stage_3\\(train\\)\ntest_s3 = predict_stage_3\\(s3, test.copy\\(\\)\\)\n\nprint\\(\"\\\\n\" + \"=\" * 70\\)\nprint\\(\"STAGE 3: HAS_BUG\"\\)\nprint\\(\"=\" * 70\\)\ntrue_bug = test['has_bug'].values\npred_bug = test_s3['s3_pred'].values\nconf_bug = test_s3['s3_confidence'].values\n\nfor code, name in [\\(0,'No Bug'\\),\\(1,'Has Bug'\\)]:\n    true_n = \\(true_bug == code\\).sum\\(\\)\n    pred_n = \\(pred_bug == code\\).sum\\(\\)\n    correct = \\(\\(true_bug == code\\) & \\(pred_bug == code\\)\\).sum\\(\\)\n    prec = correct/pred_n*100 if pred_n > 0 else 0\n    rec = correct/true_n*100 if true_n > 0 else 0\n    print\\(f\"  {name}: True={true_n}, Predicted={pred_n}, Correct={correct}, Prec={prec:.1f}%, Rec={rec:.1f}%\"\\)\n\nfor t in [0.60, 0.70, 0.80, 0.90]:\n    mask = conf_bug >= t\n    n = mask.sum\\(\\)\n    if n > 0:\n        acc = \\(true_bug[mask] == pred_bug[mask]\\).mean\\(\\)\n        print\\(f\"  t={t:.2f}: {acc*100:.1f}% acc, {n/len\\(test\\)*100:.1f}% cov \\({n} predicted\\)\"\\)\n\n# ---- Now test multiple class configs ----\nfrom cascade.framework.confidence_stage import ConfidenceStage\n\nfeatures = [c for c in FEATURES if c in train.columns]\n\n# Non-Invalid subsets\ntrain_ni = train[train['alert_summary_status'] != 3].copy\\(\\)\ntest_ni = test[test['alert_summary_status'] != 3].copy\\(\\)\n\nconfigs = [\n    \\('5-class \\(Imp,Reas,Wontfix,Fixed,Down\\)', {8:2}, {1:'Downstream',2:'Reassigned',4:'Improvement',6:'Wontfix',7:'Fixed'}, False\\),\n    \\('4-class \\(Actionable,Wontfix,Fixed,Down\\)', {8:4,2:4}, {4:'Actionable',1:'Downstream',6:'Wontfix',7:'Fixed'}, False\\),\n    \\('Binary: Imp vs NonImp', {1:0,2:0,6:0,7:0,8:0}, {0:'Non-Improvement',4:'Improvement'}, False\\),\n]\n\nfor config_name, merge, classes, use_full in configs:\n    print\\(\"\\\\n\" + \"=\" * 70\\)\n    print\\(f\"CONFIG: {config_name}\"\\)\n    print\\(\"=\" * 70\\)\n\n    tr = train.copy\\(\\) if use_full else train_ni.copy\\(\\)\n    te = test.copy\\(\\) if use_full else test_ni.copy\\(\\)\n\n    tr['target'] = tr['alert_summary_status'].replace\\(merge\\)\n    te['target'] = te['alert_summary_status'].replace\\(merge\\)\n\n    valid_codes = set\\(classes.keys\\(\\)\\)\n    tr = tr[tr['target'].isin\\(valid_codes\\)].copy\\(\\)\n    te = te[te['target'].isin\\(valid_codes\\)].copy\\(\\)\n\n    X_tr = tr[features].fillna\\(0\\).values\n    y_tr = tr['target'].values\n    X_te = te[features].fillna\\(0\\).values\n    y_te = te['target'].values\n\n    print\\(f\"\\\\nTrain: {len\\(tr\\)}, Test: {len\\(te\\)}\"\\)\n    for code in sorted\\(classes.keys\\(\\)\\):\n        n_tr = \\(y_tr == code\\).sum\\(\\)\n        n_te = \\(y_te == code\\).sum\\(\\)\n        print\\(f\"  {classes[code]} \\({code}\\): train={n_tr}, test={n_te}\"\\)\n\n    # Majority baseline\n    from collections import Counter\n    ctr = Counter\\(y_te\\)\n    majority = max\\(ctr.values\\(\\)\\) / len\\(y_te\\)\n    print\\(f\"  Majority baseline: {majority*100:.1f}%\"\\)\n\n    stage = ConfidenceStage\\(\n        name=config_name,\n        classes=classes,\n        target_accuracy=0.85,\n        random_state=RANDOM_SEED,\n    \\)\n    stage.fit\\(X_tr, y_tr, feature_names=features\\)\n    preds = stage.predict\\(X_te, return_proba=True\\)\n\n    raw = preds['predicted_raw']\n    conf = preds['confidence']\n\n    print\\(f\"\\\\nPer-class \\(raw, no threshold\\):\"\\)\n    for code in sorted\\(classes.keys\\(\\)\\):\n        true_m = y_te == code\n        pred_m = raw == code\n        both = true_m & pred_m\n        prec = both.sum\\(\\)/pred_m.sum\\(\\)*100 if pred_m.sum\\(\\) > 0 else 0\n        rec = both.sum\\(\\)/true_m.sum\\(\\)*100 if true_m.sum\\(\\) > 0 else 0\n        print\\(f\"  {classes[code]}: True={true_m.sum\\(\\)}, Pred={pred_m.sum\\(\\)}, Correct={both.sum\\(\\)}, Prec={prec:.1f}%, Rec={rec:.1f}%\"\\)\n\n    print\\(f\"\\\\nCoverage-accuracy curve:\"\\)\n    for t in [0.40, 0.50, 0.60, 0.70, 0.80, 0.90]:\n        mask = conf >= t\n        n = mask.sum\\(\\)\n        if n > 0:\n            acc = \\(y_te[mask] == raw[mask]\\).mean\\(\\)\n            print\\(f\"  t={t:.2f}: {acc*100:.1f}% acc, {n/len\\(y_te\\)*100:.1f}% cov \\({n} pred\\)\"\\)\n            for code in sorted\\(classes.keys\\(\\)\\):\n                cm = mask & \\(raw == code\\)\n                cn = cm.sum\\(\\)\n                if cn > 0:\n                    cc = \\(y_te[cm] == code\\).sum\\(\\)\n                    print\\(f\"    {classes[code]}: {cn} pred, {cc}/{cn} correct \\({cc/cn*100:.1f}%\\)\"\\)\n\n# ---- 3-class \\(whole dataset\\) ----\nprint\\(\"\\\\n\" + \"=\" * 70\\)\nprint\\(\"CONFIG: 3-class \\(Invalid, Improvement, Action-Needed\\)\"\\)\nprint\\(\"=\" * 70\\)\n\ntr3 = train.copy\\(\\)\nte3 = test.copy\\(\\)\n\ndef map3\\(s\\):\n    if s == 3: return 2\n    elif s == 4: return 1\n    else: return 0\n\ntr3['target'] = tr3['alert_summary_status'].apply\\(map3\\)\nte3['target'] = te3['alert_summary_status'].apply\\(map3\\)\nclasses3 = {0:'Action-Needed', 1:'Improvement', 2:'Invalid'}\n\nX_tr3 = tr3[features].fillna\\(0\\).values\ny_tr3 = tr3['target'].values\nX_te3 = te3[features].fillna\\(0\\).values\ny_te3 = te3['target'].values\n\nprint\\(f\"\\\\nTrain: {len\\(tr3\\)}, Test: {len\\(te3\\)}\"\\)\nfor code in sorted\\(classes3.keys\\(\\)\\):\n    n_tr = \\(y_tr3 == code\\).sum\\(\\)\n    n_te = \\(y_te3 == code\\).sum\\(\\)\n    print\\(f\"  {classes3[code]} \\({code}\\): train={n_tr}, test={n_te}\"\\)\n\nctr3 = Counter\\(y_te3\\)\nmajority3 = max\\(ctr3.values\\(\\)\\) / len\\(y_te3\\)\nprint\\(f\"  Majority baseline: {majority3*100:.1f}%\"\\)\n\nstage3c = ConfidenceStage\\(\n    name='3-class',\n    classes=classes3,\n    target_accuracy=0.85,\n    random_state=RANDOM_SEED,\n\\)\nstage3c.fit\\(X_tr3, y_tr3, feature_names=features\\)\npreds3c = stage3c.predict\\(X_te3, return_proba=True\\)\n\nraw3 = preds3c['predicted_raw']\nconf3 = preds3c['confidence']\n\nprint\\(f\"\\\\nPer-class \\(raw, no threshold\\):\"\\)\nfor code in sorted\\(classes3.keys\\(\\)\\):\n    true_m = y_te3 == code\n    pred_m = raw3 == code\n    both = true_m & pred_m\n    prec = both.sum\\(\\)/pred_m.sum\\(\\)*100 if pred_m.sum\\(\\) > 0 else 0\n    rec = both.sum\\(\\)/true_m.sum\\(\\)*100 if true_m.sum\\(\\) > 0 else 0\n    print\\(f\"  {classes3[code]}: True={true_m.sum\\(\\)}, Pred={pred_m.sum\\(\\)}, Correct={both.sum\\(\\)}, Prec={prec:.1f}%, Rec={rec:.1f}%\"\\)\n\nprint\\(f\"\\\\nCoverage-accuracy curve:\"\\)\nfor t in [0.40, 0.50, 0.60, 0.70, 0.80, 0.90]:\n    mask = conf3 >= t\n    n = mask.sum\\(\\)\n    if n > 0:\n        acc = \\(y_te3[mask] == raw3[mask]\\).mean\\(\\)\n        print\\(f\"  t={t:.2f}: {acc*100:.1f}% acc, {n/len\\(y_te3\\)*100:.1f}% cov \\({n} pred\\)\"\\)\n        for code in sorted\\(classes3.keys\\(\\)\\):\n            cm = mask & \\(raw3 == code\\)\n            cn = cm.sum\\(\\)\n            if cn > 0:\n                cc = \\(y_te3[cm] == code\\).sum\\(\\)\n                print\\(f\"    {classes3[code]}: {cn} pred, {cc}/{cn} correct \\({cc/cn*100:.1f}%\\)\"\\)\n\nPYEOF)",
      "WebFetch(domain:data.mendeley.com)",
      "WebFetch(domain:zenodo.org)",
      "Bash(# Check HuggingFace Eclipse bugs dataset pip install datasets)",
      "Bash(# Check MSR 2013 bug dataset ls /tmp/msr2013 || \\(cd /tmp && git clone --depth 1 https://github.com/ansymo/msr2013-bug_dataset.git msr2013 2>&1)",
      "Bash(# Check MSR 2013 structure ls /tmp/msr2013/data/)"
    ]
  }
}
